{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_for_ABSA for auxillary sentence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f047651e95274dc7be86bdee3d33520b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_879cf4ffb6d745159d9485e34ed657ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0539c8b30ad74299958bbde7e9d3f637",
              "IPY_MODEL_bb96af52a9a242e9997cfba03ed7176a",
              "IPY_MODEL_799ce9d97ff9465194dfe30c9cf959fc"
            ]
          }
        },
        "879cf4ffb6d745159d9485e34ed657ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0539c8b30ad74299958bbde7e9d3f637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a6eb50424524aebbc32d2e86b54df06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_527bee33bd994dfe967f124fd88f4f16"
          }
        },
        "bb96af52a9a242e9997cfba03ed7176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e47af0eeb9d24ea48ead2d90e36ebbe1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9b6832c7630410eb586b344cb3c2714"
          }
        },
        "799ce9d97ff9465194dfe30c9cf959fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d5698dc0d06493ab7ca6ee5cedeee51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 322kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5fb2cb6a6ed4a87bddbdab813f695aa"
          }
        },
        "5a6eb50424524aebbc32d2e86b54df06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "527bee33bd994dfe967f124fd88f4f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e47af0eeb9d24ea48ead2d90e36ebbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9b6832c7630410eb586b344cb3c2714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d5698dc0d06493ab7ca6ee5cedeee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5fb2cb6a6ed4a87bddbdab813f695aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d049c7877c24fee8e8b34383c468138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_369b478cc85f49ffa6a76c27dd18b48e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d606b5e5134419f924f22b83fbb9ce9",
              "IPY_MODEL_ffa732e0b383473898c763d99c4b31a8",
              "IPY_MODEL_13503a3741da426fb7697db0f002b9e0"
            ]
          }
        },
        "369b478cc85f49ffa6a76c27dd18b48e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d606b5e5134419f924f22b83fbb9ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df34939a270c46c3abff925401a28ab5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b885df89a9b4776a9fe38b4b235573c"
          }
        },
        "ffa732e0b383473898c763d99c4b31a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fe1fe2fcd9c485ea0555e9ff254fc7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2dab25114a554f23a2751c8d86bd4378"
          }
        },
        "13503a3741da426fb7697db0f002b9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3aec9dc3d2c34441b793171b21359f09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 601B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a8ffa690600423192e2ac32af00d868"
          }
        },
        "df34939a270c46c3abff925401a28ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b885df89a9b4776a9fe38b4b235573c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fe1fe2fcd9c485ea0555e9ff254fc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2dab25114a554f23a2751c8d86bd4378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aec9dc3d2c34441b793171b21359f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a8ffa690600423192e2ac32af00d868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c560f42a9913453e8fdcda55183463a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f08c7a7e10a24ea2a31ac54a0777d116",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e30710e9ff6542548ed33379f4e865b6",
              "IPY_MODEL_abd513dd05794f22bbf6c866e18e2620",
              "IPY_MODEL_0f6c6ac8a0f04082a6697b23baa38924"
            ]
          }
        },
        "f08c7a7e10a24ea2a31ac54a0777d116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e30710e9ff6542548ed33379f4e865b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_242451ed73304f94a28c802e7e0e92b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0fba2121a5c4b98b89fcace1497fec3"
          }
        },
        "abd513dd05794f22bbf6c866e18e2620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dbb32280eef48bfae0fcc41e5d3ab79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95e7bfa715b34e70816f223fd9a73a0b"
          }
        },
        "0f6c6ac8a0f04082a6697b23baa38924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5dff81fd2334c37b33bfa5e0358488f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 667kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_105ae072a0e34172a6d8737c0b0f9303"
          }
        },
        "242451ed73304f94a28c802e7e0e92b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0fba2121a5c4b98b89fcace1497fec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dbb32280eef48bfae0fcc41e5d3ab79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95e7bfa715b34e70816f223fd9a73a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5dff81fd2334c37b33bfa5e0358488f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "105ae072a0e34172a6d8737c0b0f9303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4ec651965ca4038ab706f811ad4319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d7ff4cb28764b90b3633a9b1fff203a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_668ad115e3124178aeff9589118690d4",
              "IPY_MODEL_65bba069e5ac40ab859f3a81c496ebde",
              "IPY_MODEL_7e02cd9345d64e39a4db19746c17947c"
            ]
          }
        },
        "0d7ff4cb28764b90b3633a9b1fff203a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "668ad115e3124178aeff9589118690d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e67e4615f154d4da63c80f83ebcae20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7db5a7931ea94bea918413699a9dc845"
          }
        },
        "65bba069e5ac40ab859f3a81c496ebde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab34ad2a7f9f4f269b7e331883d5c669",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77476cdeb25a4c23809f6857bba30e4c"
          }
        },
        "7e02cd9345d64e39a4db19746c17947c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3197412424f645f2989241f19734daa1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 11.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12b5269235a04198b4592795b1ed2e47"
          }
        },
        "9e67e4615f154d4da63c80f83ebcae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7db5a7931ea94bea918413699a9dc845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab34ad2a7f9f4f269b7e331883d5c669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77476cdeb25a4c23809f6857bba30e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3197412424f645f2989241f19734daa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12b5269235a04198b4592795b1ed2e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RV05/NLP-ABSA-research-papers-implementation/blob/main/BERT_for_ABSA_for_auxillary_sentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LorenzoAgnolucci/BERT_for_ABSA.git\n"
      ],
      "metadata": {
        "id": "82Cr1MqjJeUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNAX-Dsz9bYp"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/BERT_for_ABSA/requirements.txt"
      ],
      "metadata": {
        "id": "gZuWMn4vJtQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinUWR8_AM1V"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnQa1GPcoIOJ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# BERT-pair\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncOhC8Aoc6pp"
      },
      "source": [
        "#@title Choose a dataset and a task { run: \"auto\", display-mode: \"form\" }\n",
        "base_dir = \"/content/BERT_for_ABSA\" #@param {type:\"string\"}\n",
        "dataset_type = \"semeval2014\" #@param [\"sentihood\", \"semeval2014\"]\n",
        "task = \"QA_B\" #@param [\"QA_M\", \"NLI_M\", \"QA_B\", \"NLI_B\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlOFFHdiGlSw"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"positive\", 1: \"neutral\", 2: \"negative\", 3: \"conflict\", 4: \"none\"}\n",
        "    label2id = {\"positive\": 0, \"neutral\" : 1, \"negative\" : 2, \"conflict\": 3, \"none\": 4}\n",
        "\n",
        "if task.endswith(\"B\"):\n",
        "    num_classes = 2\n",
        "else:\n",
        "    if dataset_type == \"sentihood\":\n",
        "        num_classes = 3\n",
        "    elif dataset_type == \"semeval2014\":\n",
        "        num_classes = 5\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, sep=\"\\t\").values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        auxiliary_sentences.append(row[2])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, auxiliary_sentences, labels\n",
        "\n",
        "\n",
        "\n",
        "train_original_sentences, train_auxiliary_sentences, train_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/train_{task}.csv\")\n",
        "if dataset_type == \"sentihood\":\n",
        "    val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/dev_{task}.csv\")\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/test_{task}.csv\")\n",
        "test_original_sentences, test_auxiliary_sentences, test_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/test_{task}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhieorAyUUhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f047651e95274dc7be86bdee3d33520b",
            "879cf4ffb6d745159d9485e34ed657ce",
            "0539c8b30ad74299958bbde7e9d3f637",
            "bb96af52a9a242e9997cfba03ed7176a",
            "799ce9d97ff9465194dfe30c9cf959fc",
            "5a6eb50424524aebbc32d2e86b54df06",
            "527bee33bd994dfe967f124fd88f4f16",
            "e47af0eeb9d24ea48ead2d90e36ebbe1",
            "e9b6832c7630410eb586b344cb3c2714",
            "8d5698dc0d06493ab7ca6ee5cedeee51",
            "a5fb2cb6a6ed4a87bddbdab813f695aa",
            "6d049c7877c24fee8e8b34383c468138",
            "369b478cc85f49ffa6a76c27dd18b48e",
            "3d606b5e5134419f924f22b83fbb9ce9",
            "ffa732e0b383473898c763d99c4b31a8",
            "13503a3741da426fb7697db0f002b9e0",
            "df34939a270c46c3abff925401a28ab5",
            "5b885df89a9b4776a9fe38b4b235573c",
            "1fe1fe2fcd9c485ea0555e9ff254fc7e",
            "2dab25114a554f23a2751c8d86bd4378",
            "3aec9dc3d2c34441b793171b21359f09",
            "3a8ffa690600423192e2ac32af00d868",
            "c560f42a9913453e8fdcda55183463a3",
            "f08c7a7e10a24ea2a31ac54a0777d116",
            "e30710e9ff6542548ed33379f4e865b6",
            "abd513dd05794f22bbf6c866e18e2620",
            "0f6c6ac8a0f04082a6697b23baa38924",
            "242451ed73304f94a28c802e7e0e92b4",
            "d0fba2121a5c4b98b89fcace1497fec3",
            "9dbb32280eef48bfae0fcc41e5d3ab79",
            "95e7bfa715b34e70816f223fd9a73a0b",
            "f5dff81fd2334c37b33bfa5e0358488f",
            "105ae072a0e34172a6d8737c0b0f9303",
            "c4ec651965ca4038ab706f811ad4319f",
            "0d7ff4cb28764b90b3633a9b1fff203a",
            "668ad115e3124178aeff9589118690d4",
            "65bba069e5ac40ab859f3a81c496ebde",
            "7e02cd9345d64e39a4db19746c17947c",
            "9e67e4615f154d4da63c80f83ebcae20",
            "7db5a7931ea94bea918413699a9dc845",
            "ab34ad2a7f9f4f269b7e331883d5c669",
            "77476cdeb25a4c23809f6857bba30e4c",
            "3197412424f645f2989241f19734daa1",
            "12b5269235a04198b4592795b1ed2e47"
          ]
        },
        "outputId": "345f4912-23bc-4b57-a63a-20e15baafa5c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_original_sentences, train_auxiliary_sentences, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_original_sentences, val_auxiliary_sentences, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_original_sentences, test_auxiliary_sentences, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f047651e95274dc7be86bdee3d33520b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d049c7877c24fee8e8b34383c468138",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c560f42a9913453e8fdcda55183463a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4ec651965ca4038ab706f811ad4319f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQV80Jd-gQBq"
      },
      "source": [
        "import torch\n",
        "\n",
        "class ABSA_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ABSA_Dataset(train_encodings, train_labels)\n",
        "val_dataset = ABSA_Dataset(val_encodings, val_labels)\n",
        "test_dataset = ABSA_Dataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLMesy14Re3T"
      },
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import evaluation\n",
        "\n",
        "\n",
        "def get_test_labels(data_dir, dataset_type):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(f\"{data_dir}/{dataset_type}/BERT-pair/test_NLI_M.csv\", header=0, sep=\"\\t\").values.tolist()\n",
        "    for row in data:\n",
        "        labels.append(row[3])\n",
        "    return labels\n",
        "\n",
        "\n",
        "def get_predictions(data, task, dataset_type):\n",
        "    predicted_labels = []\n",
        "    scores = []\n",
        "    if task.endswith(\"B\"):\n",
        "        if dataset_type == \"sentihood\":\n",
        "            if task.endswith(\"B\"):\n",
        "                count_aspect_rows = 0\n",
        "                current_aspect_scores = []\n",
        "                for row in data:\n",
        "                    current_aspect_scores.append(row[2])\n",
        "                    count_aspect_rows += 1\n",
        "                    if count_aspect_rows % 3 == 0:\n",
        "                        sum_current_aspect_scores = np.sum(current_aspect_scores)\n",
        "                        current_aspect_scores = [score / sum_current_aspect_scores for score in current_aspect_scores]\n",
        "                        scores.append(current_aspect_scores)\n",
        "                        predicted_labels.append(np.argmax(current_aspect_scores))\n",
        "                        current_aspect_scores = []\n",
        "        elif dataset_type == \"semeval2014\":\n",
        "            if task.endswith(\"B\"):\n",
        "                count_aspect_rows = 0\n",
        "                current_aspect_scores = []\n",
        "                for row in data:\n",
        "                    current_aspect_scores.append(row[2])\n",
        "                    count_aspect_rows += 1\n",
        "                    if count_aspect_rows % 5 == 0:\n",
        "                        sum_current_aspect_scores = np.sum(current_aspect_scores)\n",
        "                        current_aspect_scores = [score / sum_current_aspect_scores for score in current_aspect_scores]\n",
        "                        scores.append(current_aspect_scores)\n",
        "                        predicted_labels.append(np.argmax(current_aspect_scores))\n",
        "                        current_aspect_scores = []\n",
        "    return predicted_labels, scores\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    def compute_metrics(predictions):\n",
        "        scores = [softmax(prediction) for prediction in predictions[0]]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "        if task.endswith(\"B\"):\n",
        "            data = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "            predicted_labels, scores = get_predictions(data, task, dataset_type)\n",
        "        test_labels = get_test_labels(f\"{base_dir}/data\", dataset_type)\n",
        "        metrics = {}\n",
        "        metrics[\"strict_acc\"] = evaluation.compute_sentihood_aspect_strict_accuracy(test_labels, predicted_labels)\n",
        "        metrics[\"F1\"] = evaluation.compute_sentihood_aspect_macro_F1(test_labels, predicted_labels)\n",
        "        metrics[\"aspect_AUC\"] = evaluation.compute_sentihood_aspect_macro_AUC(test_labels, scores)\n",
        "        sentiment_macro_AUC, sentiment_accuracy = evaluation.compute_sentihood_sentiment_classification_metrics(test_labels, scores)\n",
        "        metrics[\"sentiment_acc\"] = sentiment_accuracy\n",
        "        metrics[\"sentiment_AUC\"] = sentiment_macro_AUC\n",
        "        return metrics\n",
        "\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    def compute_metrics(predictions):\n",
        "        scores = [softmax(prediction) for prediction in predictions[0]]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "        if task.endswith(\"B\"):\n",
        "            data = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "            predicted_labels, scores = get_predictions(data, task, dataset_type)\n",
        "        test_labels = get_test_labels(f\"{base_dir}/data\", dataset_type)\n",
        "        metrics = {}\n",
        "        p, r, f1 = evaluation.compute_semeval_PRF(test_labels, predicted_labels)\n",
        "        metrics[\"P\"] = p\n",
        "        metrics[\"R\"] = r\n",
        "        metrics[\"F1\"] = f1\n",
        "        metrics[\"4-way\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 4)\n",
        "        metrics[\"3-way\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 3)\n",
        "        metrics[\"binary\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 2)\n",
        "        return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TNnE3UesI1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c50a115d-9bb8-4048-c65f-2b390f54bfc9"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertConfig\n",
        "\n",
        "from transformers import logging\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 24\n",
        "num_steps = len(train_dataset) * epochs // batch_size\n",
        "warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = f'{base_dir}/models/{dataset_type}/BERT-pair/{task}/',          \n",
        "    num_train_epochs = epochs,              \n",
        "    per_device_train_batch_size = batch_size,  \n",
        "    per_device_eval_batch_size = batch_size,   \n",
        "    warmup_steps = warmup_steps,   \n",
        "    weight_decay = 0.01,               \n",
        "    logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-pair/{task}/',            \n",
        "    logging_steps = 10,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    save_steps = save_steps\n",
        ")\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    architectures = ['BertForSequenceClassification'],\n",
        "    hidden_size = 768,\n",
        "    num_hidden_layers = 12,\n",
        "    num_attention_heads = 12,\n",
        "    hidden_dropout_prob = 0.1,\n",
        "    num_labels = num_classes\n",
        ")    \n",
        "\n",
        "load_finetuned_model = False\n",
        "if not load_finetuned_model:\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,                         \n",
        "        args=training_args,                  \n",
        "        train_dataset=train_dataset,         \n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics             \n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "    model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\")\n",
        "\n",
        "else:\n",
        "    model = BertForSequenceClassification.from_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\")\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,                         \n",
        "        args=training_args,                  \n",
        "        train_dataset=train_dataset,         \n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics             \n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.15.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 76100\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='257' max='3171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 257/3171 03:38 < 41:31, 1.17 it/s, Epoch 0.08/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-69516fd4334a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m                 ):\n\u001b[1;32m   1339\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_33_i5bR7tS"
      },
      "source": [
        "evaluation_result = trainer.evaluate(test_dataset)\n",
        "print(evaluation_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOr0LtJdbPjM"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "\n",
        "scores = [softmax(prediction) for prediction in results.predictions]\n",
        "predicted_labels = [np.argmax(x) for x in scores]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUgiS6XM-lNE"
      },
      "source": [
        "csv_output = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "df = pd.DataFrame(csv_output)\n",
        "df[0] = df[0].astype(\"int\")\n",
        "if task.endswith(\"B\"):\n",
        "    header = [\"predicted_label\", \"no\", \"yes\"]\n",
        "else:\n",
        "    header = [\"predicted_label\"]\n",
        "    for label in label2id.keys():\n",
        "        header.append(label)\n",
        "df.to_csv(f\"{base_dir}/results/{dataset_type}/BERT-pair/{task}.csv\", index=False, header=header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t8j0FJWhV6R"
      },
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import evaluation\n",
        "evaluation.main(task, dataset_type, f\"{base_dir}/data\", f\"{base_dir}/results\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DVoml__ohye"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# BERT-single\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us9ezWVjqKBd"
      },
      "source": [
        "#@title Choose a dataset and a task { run: \"auto\", display-mode: \"form\" }\n",
        "base_dir = \"/gdrive/MyDrive/Machine_Learning\" #@param {type:\"string\"}\n",
        "dataset_type = \"semeval2014\" #@param [\"sentihood\", \"semeval2014\"]\n",
        "task = \"single\" #@param [\"single\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huv7NHH0yh5f"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"positive\", 1: \"neutral\", 2: \"negative\", 3: \"conflict\", 4: \"none\"}\n",
        "    label2id = {\"positive\": 0, \"neutral\" : 1, \"negative\" : 2, \"conflict\": 3, \"none\": 4}\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    num_classes = 3\n",
        "    locations = [\"location_1_\", \"location_2_\"]\n",
        "    aspects = [\"general\", \"price\", \"safety\", \"transit location\"]\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    num_classes = 5\n",
        "    locations = [\"\"]\n",
        "    aspects = [\"ambience\", \"anecdotes\", \"food\", \"price\", \"service\"]\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, sep=\"\\t\").values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, labels\n",
        "\n",
        "\n",
        "train_original_sentences = {}\n",
        "train_labels = {}\n",
        "val_original_sentences = {}\n",
        "val_labels = {}\n",
        "test_original_sentences = {}\n",
        "test_labels = {}\n",
        "\n",
        "for location in locations:\n",
        "    train_original_sentences[location] = {}\n",
        "    train_labels[location] = {}\n",
        "    val_original_sentences[location] = {}\n",
        "    val_labels[location] = {}\n",
        "    test_original_sentences[location] = {}\n",
        "    test_labels[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_original_sentences[location][aspect], train_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/train.csv\")\n",
        "        if dataset_type == \"sentihood\":\n",
        "            val_original_sentences[location][aspect], val_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/dev.csv\")\n",
        "        elif dataset_type == \"semeval2014\":\n",
        "            val_original_sentences[location][aspect], val_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/test.csv\")\n",
        "        test_original_sentences[location][aspect], test_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smEGjmdiy90j"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = {}\n",
        "val_encodings = {}\n",
        "test_encodings = {}\n",
        "for location in locations:\n",
        "    train_encodings[location] = {}\n",
        "    val_encodings[location] = {}\n",
        "    test_encodings[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_encodings[location][aspect] = tokenizer(train_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        val_encodings[location][aspect] = tokenizer(val_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        test_encodings[location][aspect] = tokenizer(test_original_sentences[location][aspect], truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_FhmCkKzGDs"
      },
      "source": [
        "import torch\n",
        "\n",
        "class ABSA_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = {}\n",
        "val_dataset = {}\n",
        "test_dataset = {}\n",
        "for location in locations:\n",
        "    train_dataset[location] = {}\n",
        "    val_dataset[location] = {}\n",
        "    test_dataset[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_dataset[location][aspect] = ABSA_Dataset(train_encodings[location][aspect], train_labels[location][aspect])\n",
        "        val_dataset[location][aspect] = ABSA_Dataset(val_encodings[location][aspect], val_labels[location][aspect])\n",
        "        test_dataset[location][aspect] = ABSA_Dataset(test_encodings[location][aspect], test_labels[location][aspect])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zubkNmxFzLTy"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertConfig\n",
        "from transformers import logging\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 4\n",
        "batch_size = 24\n",
        "\n",
        "header = [\"predicted_label\"]\n",
        "for label in label2id.keys():\n",
        "    header.append(label)\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "        'bert-base-uncased',\n",
        "        architectures = ['BertForSequenceClassification'],\n",
        "        hidden_size = 768,\n",
        "        num_hidden_layers = 12,\n",
        "        num_attention_heads = 12,\n",
        "        hidden_dropout_prob = 0.1,\n",
        "        num_labels = num_classes\n",
        "    )    \n",
        "\n",
        "for location in locations:\n",
        "    for aspect in aspects:\n",
        "        num_steps = len(train_dataset[location][aspect]) * epochs // batch_size\n",
        "        warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "        save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir = f'{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/',          \n",
        "            num_train_epochs = epochs,              \n",
        "            per_device_train_batch_size = batch_size,  \n",
        "            per_device_eval_batch_size = batch_size,   \n",
        "            warmup_steps = warmup_steps,   \n",
        "            weight_decay = 0.01,               \n",
        "            logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-single/{location}{aspect}/',            \n",
        "            logging_steps = 10,\n",
        "            evaluation_strategy = 'epoch',\n",
        "            learning_rate = 2e-5,\n",
        "            save_steps = save_steps,\n",
        "            seed=21\n",
        "        )\n",
        "\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,                         \n",
        "            args=training_args,                  \n",
        "            train_dataset=train_dataset[location][aspect],         \n",
        "            eval_dataset=val_dataset[location][aspect]             \n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/last_step\")\n",
        "\n",
        "        results = trainer.predict(test_dataset[location][aspect])\n",
        "\n",
        "        scores = [softmax(prediction) for prediction in results.predictions]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "\n",
        "        csv_output = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "        df = pd.DataFrame(csv_output)\n",
        "        df[0] = df[0].astype(\"int\")\n",
        "        df.to_csv(f\"{base_dir}/results/{dataset_type}/BERT-single/{location}{aspect}.csv\", index=False, header=header)\n",
        "\n",
        "        del training_args\n",
        "        del model\n",
        "        del trainer\n",
        "        del results\n",
        "        del scores\n",
        "        del predicted_labels\n",
        "        del csv_output\n",
        "        del df\n",
        "        gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XE4Ts6ezgaT"
      },
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import evaluation\n",
        "\n",
        "\n",
        "evaluation.main(task, dataset_type, f\"{base_dir}/data\", f\"{base_dir}/results\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epQjGhtGlntP"
      },
      "source": [
        "# Paper Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZZAWOVjhRpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f631c01-aebb-4d6d-c8d5-51d1691fc0c7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HSLCY/ABSA-BERT-pair.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBlAhGcxgmsP",
        "outputId": "7447f3dc-1c9e-4f70-a121-8e4af0567d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ABSA-BERT-pair'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 1 (delta 0), pack-reused 33\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltVH-Do9clTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dc448f-271a-4fe7-e0d9-d4e0936c84fc"
      },
      "source": [
        "%cd ABSA-BERT-pair/\n",
        "%cd generate/\n",
        "!bash make.sh sentihood\n",
        "!bash make.sh semeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ABSA-BERT-pair\n",
            "/content/ABSA-BERT-pair/generate\n",
            "len(train) =  24\n",
            "len(val) =  8\n",
            "len(test) =  8\n",
            "len(train) =  24\n",
            "len(val) =  8\n",
            "len(test) =  8\n",
            "len(train) =  24\n",
            "len(val) =  8\n",
            "len(test) =  8\n",
            "len(train) =  24\n",
            "len(val) =  8\n",
            "len(test) =  8\n",
            "Finished!\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKIL8rhMdRGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656cdb3b-715b-482b-c1db-81fd521fbe09"
      },
      "source": [
        "%cd ../\n",
        "!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
        "!unzip -d uncased_L-12_H-768_A-12 uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ABSA-BERT-pair\n",
            "--2021-12-30 18:14:00--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 74.125.132.128, 74.125.201.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 408102251 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 389.20M   193MB/s    in 2.0s    \n",
            "\n",
            "2021-12-30 18:14:02 (193 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [408102251/408102251]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMVmQLUhiPid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501cf120-c234-4931-9756-10b6a22754b4"
      },
      "source": [
        "!python convert_tf_checkpoint_to_pytorch.py \\\n",
        "--tf_checkpoint_path uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
        "--bert_config_file uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "--pytorch_dump_path uncased_L-12_H-768_A-12/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting TensorFlow checkpoint from uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "Loading bert/embeddings/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/embeddings/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/embeddings/position_embeddings with shape [512, 768]\n",
            "Numpy array shape (512, 768)\n",
            "Loading bert/embeddings/token_type_embeddings with shape [2, 768]\n",
            "Numpy array shape (2, 768)\n",
            "Loading bert/embeddings/word_embeddings with shape [30522, 768]\n",
            "Numpy array shape (30522, 768)\n",
            "Loading bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/pooler/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/pooler/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading cls/predictions/output_bias with shape [30522]\n",
            "Numpy array shape (30522,)\n",
            "Loading cls/predictions/transform/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading cls/seq_relationship/output_bias with shape [2]\n",
            "Numpy array shape (2,)\n",
            "Loading cls/seq_relationship/output_weights with shape [2, 768]\n",
            "Numpy array shape (2, 768)\n",
            "Loading embeddings/LayerNorm/beta\n",
            "Loading embeddings/LayerNorm/gamma\n",
            "Loading embeddings/position_embeddings\n",
            "Loading embeddings/token_type_embeddings\n",
            "Loading embeddings/word_embeddings\n",
            "Loading encoder/layer_0/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_0/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_0/attention/output/dense/bias\n",
            "Loading encoder/layer_0/attention/output/dense/kernel\n",
            "Loading encoder/layer_0/attention/self/key/bias\n",
            "Loading encoder/layer_0/attention/self/key/kernel\n",
            "Loading encoder/layer_0/attention/self/query/bias\n",
            "Loading encoder/layer_0/attention/self/query/kernel\n",
            "Loading encoder/layer_0/attention/self/value/bias\n",
            "Loading encoder/layer_0/attention/self/value/kernel\n",
            "Loading encoder/layer_0/intermediate/dense/bias\n",
            "Loading encoder/layer_0/intermediate/dense/kernel\n",
            "Loading encoder/layer_0/output/LayerNorm/beta\n",
            "Loading encoder/layer_0/output/LayerNorm/gamma\n",
            "Loading encoder/layer_0/output/dense/bias\n",
            "Loading encoder/layer_0/output/dense/kernel\n",
            "Loading encoder/layer_1/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_1/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_1/attention/output/dense/bias\n",
            "Loading encoder/layer_1/attention/output/dense/kernel\n",
            "Loading encoder/layer_1/attention/self/key/bias\n",
            "Loading encoder/layer_1/attention/self/key/kernel\n",
            "Loading encoder/layer_1/attention/self/query/bias\n",
            "Loading encoder/layer_1/attention/self/query/kernel\n",
            "Loading encoder/layer_1/attention/self/value/bias\n",
            "Loading encoder/layer_1/attention/self/value/kernel\n",
            "Loading encoder/layer_1/intermediate/dense/bias\n",
            "Loading encoder/layer_1/intermediate/dense/kernel\n",
            "Loading encoder/layer_1/output/LayerNorm/beta\n",
            "Loading encoder/layer_1/output/LayerNorm/gamma\n",
            "Loading encoder/layer_1/output/dense/bias\n",
            "Loading encoder/layer_1/output/dense/kernel\n",
            "Loading encoder/layer_10/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_10/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_10/attention/output/dense/bias\n",
            "Loading encoder/layer_10/attention/output/dense/kernel\n",
            "Loading encoder/layer_10/attention/self/key/bias\n",
            "Loading encoder/layer_10/attention/self/key/kernel\n",
            "Loading encoder/layer_10/attention/self/query/bias\n",
            "Loading encoder/layer_10/attention/self/query/kernel\n",
            "Loading encoder/layer_10/attention/self/value/bias\n",
            "Loading encoder/layer_10/attention/self/value/kernel\n",
            "Loading encoder/layer_10/intermediate/dense/bias\n",
            "Loading encoder/layer_10/intermediate/dense/kernel\n",
            "Loading encoder/layer_10/output/LayerNorm/beta\n",
            "Loading encoder/layer_10/output/LayerNorm/gamma\n",
            "Loading encoder/layer_10/output/dense/bias\n",
            "Loading encoder/layer_10/output/dense/kernel\n",
            "Loading encoder/layer_11/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_11/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_11/attention/output/dense/bias\n",
            "Loading encoder/layer_11/attention/output/dense/kernel\n",
            "Loading encoder/layer_11/attention/self/key/bias\n",
            "Loading encoder/layer_11/attention/self/key/kernel\n",
            "Loading encoder/layer_11/attention/self/query/bias\n",
            "Loading encoder/layer_11/attention/self/query/kernel\n",
            "Loading encoder/layer_11/attention/self/value/bias\n",
            "Loading encoder/layer_11/attention/self/value/kernel\n",
            "Loading encoder/layer_11/intermediate/dense/bias\n",
            "Loading encoder/layer_11/intermediate/dense/kernel\n",
            "Loading encoder/layer_11/output/LayerNorm/beta\n",
            "Loading encoder/layer_11/output/LayerNorm/gamma\n",
            "Loading encoder/layer_11/output/dense/bias\n",
            "Loading encoder/layer_11/output/dense/kernel\n",
            "Loading encoder/layer_2/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_2/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_2/attention/output/dense/bias\n",
            "Loading encoder/layer_2/attention/output/dense/kernel\n",
            "Loading encoder/layer_2/attention/self/key/bias\n",
            "Loading encoder/layer_2/attention/self/key/kernel\n",
            "Loading encoder/layer_2/attention/self/query/bias\n",
            "Loading encoder/layer_2/attention/self/query/kernel\n",
            "Loading encoder/layer_2/attention/self/value/bias\n",
            "Loading encoder/layer_2/attention/self/value/kernel\n",
            "Loading encoder/layer_2/intermediate/dense/bias\n",
            "Loading encoder/layer_2/intermediate/dense/kernel\n",
            "Loading encoder/layer_2/output/LayerNorm/beta\n",
            "Loading encoder/layer_2/output/LayerNorm/gamma\n",
            "Loading encoder/layer_2/output/dense/bias\n",
            "Loading encoder/layer_2/output/dense/kernel\n",
            "Loading encoder/layer_3/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_3/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_3/attention/output/dense/bias\n",
            "Loading encoder/layer_3/attention/output/dense/kernel\n",
            "Loading encoder/layer_3/attention/self/key/bias\n",
            "Loading encoder/layer_3/attention/self/key/kernel\n",
            "Loading encoder/layer_3/attention/self/query/bias\n",
            "Loading encoder/layer_3/attention/self/query/kernel\n",
            "Loading encoder/layer_3/attention/self/value/bias\n",
            "Loading encoder/layer_3/attention/self/value/kernel\n",
            "Loading encoder/layer_3/intermediate/dense/bias\n",
            "Loading encoder/layer_3/intermediate/dense/kernel\n",
            "Loading encoder/layer_3/output/LayerNorm/beta\n",
            "Loading encoder/layer_3/output/LayerNorm/gamma\n",
            "Loading encoder/layer_3/output/dense/bias\n",
            "Loading encoder/layer_3/output/dense/kernel\n",
            "Loading encoder/layer_4/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_4/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_4/attention/output/dense/bias\n",
            "Loading encoder/layer_4/attention/output/dense/kernel\n",
            "Loading encoder/layer_4/attention/self/key/bias\n",
            "Loading encoder/layer_4/attention/self/key/kernel\n",
            "Loading encoder/layer_4/attention/self/query/bias\n",
            "Loading encoder/layer_4/attention/self/query/kernel\n",
            "Loading encoder/layer_4/attention/self/value/bias\n",
            "Loading encoder/layer_4/attention/self/value/kernel\n",
            "Loading encoder/layer_4/intermediate/dense/bias\n",
            "Loading encoder/layer_4/intermediate/dense/kernel\n",
            "Loading encoder/layer_4/output/LayerNorm/beta\n",
            "Loading encoder/layer_4/output/LayerNorm/gamma\n",
            "Loading encoder/layer_4/output/dense/bias\n",
            "Loading encoder/layer_4/output/dense/kernel\n",
            "Loading encoder/layer_5/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_5/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_5/attention/output/dense/bias\n",
            "Loading encoder/layer_5/attention/output/dense/kernel\n",
            "Loading encoder/layer_5/attention/self/key/bias\n",
            "Loading encoder/layer_5/attention/self/key/kernel\n",
            "Loading encoder/layer_5/attention/self/query/bias\n",
            "Loading encoder/layer_5/attention/self/query/kernel\n",
            "Loading encoder/layer_5/attention/self/value/bias\n",
            "Loading encoder/layer_5/attention/self/value/kernel\n",
            "Loading encoder/layer_5/intermediate/dense/bias\n",
            "Loading encoder/layer_5/intermediate/dense/kernel\n",
            "Loading encoder/layer_5/output/LayerNorm/beta\n",
            "Loading encoder/layer_5/output/LayerNorm/gamma\n",
            "Loading encoder/layer_5/output/dense/bias\n",
            "Loading encoder/layer_5/output/dense/kernel\n",
            "Loading encoder/layer_6/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_6/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_6/attention/output/dense/bias\n",
            "Loading encoder/layer_6/attention/output/dense/kernel\n",
            "Loading encoder/layer_6/attention/self/key/bias\n",
            "Loading encoder/layer_6/attention/self/key/kernel\n",
            "Loading encoder/layer_6/attention/self/query/bias\n",
            "Loading encoder/layer_6/attention/self/query/kernel\n",
            "Loading encoder/layer_6/attention/self/value/bias\n",
            "Loading encoder/layer_6/attention/self/value/kernel\n",
            "Loading encoder/layer_6/intermediate/dense/bias\n",
            "Loading encoder/layer_6/intermediate/dense/kernel\n",
            "Loading encoder/layer_6/output/LayerNorm/beta\n",
            "Loading encoder/layer_6/output/LayerNorm/gamma\n",
            "Loading encoder/layer_6/output/dense/bias\n",
            "Loading encoder/layer_6/output/dense/kernel\n",
            "Loading encoder/layer_7/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_7/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_7/attention/output/dense/bias\n",
            "Loading encoder/layer_7/attention/output/dense/kernel\n",
            "Loading encoder/layer_7/attention/self/key/bias\n",
            "Loading encoder/layer_7/attention/self/key/kernel\n",
            "Loading encoder/layer_7/attention/self/query/bias\n",
            "Loading encoder/layer_7/attention/self/query/kernel\n",
            "Loading encoder/layer_7/attention/self/value/bias\n",
            "Loading encoder/layer_7/attention/self/value/kernel\n",
            "Loading encoder/layer_7/intermediate/dense/bias\n",
            "Loading encoder/layer_7/intermediate/dense/kernel\n",
            "Loading encoder/layer_7/output/LayerNorm/beta\n",
            "Loading encoder/layer_7/output/LayerNorm/gamma\n",
            "Loading encoder/layer_7/output/dense/bias\n",
            "Loading encoder/layer_7/output/dense/kernel\n",
            "Loading encoder/layer_8/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_8/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_8/attention/output/dense/bias\n",
            "Loading encoder/layer_8/attention/output/dense/kernel\n",
            "Loading encoder/layer_8/attention/self/key/bias\n",
            "Loading encoder/layer_8/attention/self/key/kernel\n",
            "Loading encoder/layer_8/attention/self/query/bias\n",
            "Loading encoder/layer_8/attention/self/query/kernel\n",
            "Loading encoder/layer_8/attention/self/value/bias\n",
            "Loading encoder/layer_8/attention/self/value/kernel\n",
            "Loading encoder/layer_8/intermediate/dense/bias\n",
            "Loading encoder/layer_8/intermediate/dense/kernel\n",
            "Loading encoder/layer_8/output/LayerNorm/beta\n",
            "Loading encoder/layer_8/output/LayerNorm/gamma\n",
            "Loading encoder/layer_8/output/dense/bias\n",
            "Loading encoder/layer_8/output/dense/kernel\n",
            "Loading encoder/layer_9/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_9/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_9/attention/output/dense/bias\n",
            "Loading encoder/layer_9/attention/output/dense/kernel\n",
            "Loading encoder/layer_9/attention/self/key/bias\n",
            "Loading encoder/layer_9/attention/self/key/kernel\n",
            "Loading encoder/layer_9/attention/self/query/bias\n",
            "Loading encoder/layer_9/attention/self/query/kernel\n",
            "Loading encoder/layer_9/attention/self/value/bias\n",
            "Loading encoder/layer_9/attention/self/value/kernel\n",
            "Loading encoder/layer_9/intermediate/dense/bias\n",
            "Loading encoder/layer_9/intermediate/dense/kernel\n",
            "Loading encoder/layer_9/output/LayerNorm/beta\n",
            "Loading encoder/layer_9/output/LayerNorm/gamma\n",
            "Loading encoder/layer_9/output/dense/bias\n",
            "Loading encoder/layer_9/output/dense/kernel\n",
            "Loading pooler/dense/bias\n",
            "Loading pooler/dense/kernel\n",
            "Loading redictions/output_bias\n",
            "Skipping\n",
            "Loading redictions/transform/LayerNorm/beta\n",
            "Skipping\n",
            "Loading redictions/transform/LayerNorm/gamma\n",
            "Skipping\n",
            "Loading redictions/transform/dense/bias\n",
            "Skipping\n",
            "Loading redictions/transform/dense/kernel\n",
            "Skipping\n",
            "Loading eq_relationship/output_bias\n",
            "Skipping\n",
            "Loading eq_relationship/output_weights\n",
            "Skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/ABSA-BERT-pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0BJoWJ9fkMi",
        "outputId": "277e6a5d-a984-4305-daf7-ad4ce6e68563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ABSA-BERT-pair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKj6RmGCdTse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59543d39-b00f-47b8-8f67-bdd9e0e1d01e"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python run_classifier_TABSA.py \\\n",
        "--task_name sentihood_QA_M \\\n",
        "--data_dir data/sentihood/bert-pair/ \\\n",
        "--vocab_file uncased_L-12_H-768_A-12/vocab.txt \\\n",
        "--bert_config_file uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "--init_checkpoint uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
        "--eval_test \\\n",
        "--do_lower_case \\\n",
        "--max_seq_length 512 \\\n",
        "--train_batch_size 1 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--num_train_epochs 20 \\\n",
        "--output_dir results20/ \\\n",
        "--seed 42"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/30/2021 18:29:19 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n",
            "0\n",
            "guid= train-0\n",
            "text_a= you would likely have to share a bedsit first of all you need a student visa- you need to go to the uk immigration and visa site and read the rules and the procedure a place called location - 1 20 mins by train from london location - 2\n",
            "text_b= what do you think of the general of location - 1 ?\n",
            "label= None\n",
            "\r  0% 0/24 [00:00<?, ?it/s]\r100% 24/24 [00:00<00:00, 857.99it/s]\n",
            "12/30/2021 18:29:19 - INFO - __main__ -   ***** Running training *****\n",
            "12/30/2021 18:29:19 - INFO - __main__ -     Num examples = 24\n",
            "12/30/2021 18:29:19 - INFO - __main__ -     Batch size = 1\n",
            "12/30/2021 18:29:19 - INFO - __main__ -     Num steps = 480\n",
            "0\n",
            "guid= test-0\n",
            "text_a= you want good venues , restaurants pubs and clubs with good looking chicks that are easy , live in location - 1\n",
            "text_b= what do you think of the general of location - 1 ?\n",
            "label= None\n",
            "100% 8/8 [00:00<00:00, 1680.66it/s]\n",
            "output_log_file= results20/log.txt\n",
            "Epoch:   0% 0/20 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A/content/ABSA-BERT-pair/optimization.py:146: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "\n",
            "Iteration:   4% 1/24 [00:00<00:09,  2.31it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.53it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.67it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.74it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.78it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.78it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.78it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.80it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.80it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:05<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.85it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.85it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.81it/s]\n",
            "12/30/2021 18:29:33 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:29:33 - INFO - __main__ -     epoch = 1\n",
            "\n",
            "12/30/2021 18:29:33 - INFO - __main__ -     global_step = 24\n",
            "\n",
            "12/30/2021 18:29:33 - INFO - __main__ -     loss = 0.5176638447834799\n",
            "\n",
            "12/30/2021 18:29:33 - INFO - __main__ -     test_loss = 0.6211899518966675\n",
            "\n",
            "12/30/2021 18:29:33 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:   5% 1/20 [00:09<02:52,  9.08s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.67it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.74it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.86it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:29:42 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:29:42 - INFO - __main__ -     epoch = 2\n",
            "\n",
            "12/30/2021 18:29:42 - INFO - __main__ -     global_step = 48\n",
            "\n",
            "12/30/2021 18:29:42 - INFO - __main__ -     loss = 0.23513206941909934\n",
            "\n",
            "12/30/2021 18:29:42 - INFO - __main__ -     test_loss = 0.928479015827179\n",
            "\n",
            "12/30/2021 18:29:42 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  10% 2/20 [00:18<02:42,  9.04s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.70it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.77it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.82it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.80it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.82it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.82it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.82it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:29:51 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:29:51 - INFO - __main__ -     epoch = 3\n",
            "\n",
            "12/30/2021 18:29:51 - INFO - __main__ -     global_step = 72\n",
            "\n",
            "12/30/2021 18:29:51 - INFO - __main__ -     loss = 0.28499246316884336\n",
            "\n",
            "12/30/2021 18:29:51 - INFO - __main__ -     test_loss = 0.7072614431381226\n",
            "\n",
            "12/30/2021 18:29:51 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  15% 3/20 [00:27<02:33,  9.04s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.67it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.82it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.79it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.82it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:00 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:00 - INFO - __main__ -     epoch = 4\n",
            "\n",
            "12/30/2021 18:30:00 - INFO - __main__ -     global_step = 96\n",
            "\n",
            "12/30/2021 18:30:00 - INFO - __main__ -     loss = 0.17914202336154025\n",
            "\n",
            "12/30/2021 18:30:00 - INFO - __main__ -     test_loss = 0.942634105682373\n",
            "\n",
            "12/30/2021 18:30:00 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  20% 4/20 [00:36<02:24,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.68it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.83it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.84it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.84it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.82it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.85it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.85it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:09 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:09 - INFO - __main__ -     epoch = 5\n",
            "\n",
            "12/30/2021 18:30:09 - INFO - __main__ -     global_step = 120\n",
            "\n",
            "12/30/2021 18:30:09 - INFO - __main__ -     loss = 0.27514093422602554\n",
            "\n",
            "12/30/2021 18:30:09 - INFO - __main__ -     test_loss = 0.7477111220359802\n",
            "\n",
            "12/30/2021 18:30:09 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  25% 5/20 [00:45<02:15,  9.02s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.63it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.75it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.79it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.83it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.82it/s]\n",
            "12/30/2021 18:30:18 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:18 - INFO - __main__ -     epoch = 6\n",
            "\n",
            "12/30/2021 18:30:18 - INFO - __main__ -     global_step = 144\n",
            "\n",
            "12/30/2021 18:30:18 - INFO - __main__ -     loss = 0.20260889747199448\n",
            "\n",
            "12/30/2021 18:30:18 - INFO - __main__ -     test_loss = 0.6945093870162964\n",
            "\n",
            "12/30/2021 18:30:18 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  30% 6/20 [00:54<02:06,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.65it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.74it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.86it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.81it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.82it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:27 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:27 - INFO - __main__ -     epoch = 7\n",
            "\n",
            "12/30/2021 18:30:27 - INFO - __main__ -     global_step = 168\n",
            "\n",
            "12/30/2021 18:30:27 - INFO - __main__ -     loss = 0.17620897236823416\n",
            "\n",
            "12/30/2021 18:30:27 - INFO - __main__ -     test_loss = 0.7129395008087158\n",
            "\n",
            "12/30/2021 18:30:27 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  35% 7/20 [01:03<01:57,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.65it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.82it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.84it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.81it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.82it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.83it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.83it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:36 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:36 - INFO - __main__ -     epoch = 8\n",
            "\n",
            "12/30/2021 18:30:36 - INFO - __main__ -     global_step = 192\n",
            "\n",
            "12/30/2021 18:30:36 - INFO - __main__ -     loss = 0.22158305582221752\n",
            "\n",
            "12/30/2021 18:30:36 - INFO - __main__ -     test_loss = 0.7941231727600098\n",
            "\n",
            "12/30/2021 18:30:36 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  40% 8/20 [01:12<01:48,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.65it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.73it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.83it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:45 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:45 - INFO - __main__ -     epoch = 9\n",
            "\n",
            "12/30/2021 18:30:45 - INFO - __main__ -     global_step = 216\n",
            "\n",
            "12/30/2021 18:30:45 - INFO - __main__ -     loss = 0.16985263656048724\n",
            "\n",
            "12/30/2021 18:30:45 - INFO - __main__ -     test_loss = 0.6367455124855042\n",
            "\n",
            "12/30/2021 18:30:45 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  45% 9/20 [01:21<01:39,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.68it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.82it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:30:54 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:30:54 - INFO - __main__ -     epoch = 10\n",
            "\n",
            "12/30/2021 18:30:54 - INFO - __main__ -     global_step = 240\n",
            "\n",
            "12/30/2021 18:30:54 - INFO - __main__ -     loss = 0.13654854033908728\n",
            "\n",
            "12/30/2021 18:30:54 - INFO - __main__ -     test_loss = 0.6038177013397217\n",
            "\n",
            "12/30/2021 18:30:54 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  50% 10/20 [01:30<01:30,  9.04s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.58it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.72it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.85it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:31:03 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:03 - INFO - __main__ -     epoch = 11\n",
            "\n",
            "12/30/2021 18:31:03 - INFO - __main__ -     global_step = 264\n",
            "\n",
            "12/30/2021 18:31:03 - INFO - __main__ -     loss = 0.1168414456769824\n",
            "\n",
            "12/30/2021 18:31:03 - INFO - __main__ -     test_loss = 0.6147627234458923\n",
            "\n",
            "12/30/2021 18:31:03 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  55% 11/20 [01:39<01:21,  9.03s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:14,  1.62it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:10,  2.14it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:08,  2.41it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.55it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:02<00:07,  2.65it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.71it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.75it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:03<00:05,  2.77it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.79it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.80it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:04<00:04,  2.80it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.81it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:05<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.81it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:08<00:00,  2.82it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.82it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.74it/s]\n",
            "12/30/2021 18:31:13 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:13 - INFO - __main__ -     epoch = 12\n",
            "\n",
            "12/30/2021 18:31:13 - INFO - __main__ -     global_step = 288\n",
            "\n",
            "12/30/2021 18:31:13 - INFO - __main__ -     loss = 0.16359895469092103\n",
            "\n",
            "12/30/2021 18:31:13 - INFO - __main__ -     test_loss = 0.6577839255332947\n",
            "\n",
            "12/30/2021 18:31:13 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  60% 12/20 [01:48<01:12,  9.12s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.63it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.73it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.82it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.81it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.80it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.81it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.81it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.82it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.83it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.83it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.82it/s]\n",
            "12/30/2021 18:31:22 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:22 - INFO - __main__ -     epoch = 13\n",
            "\n",
            "12/30/2021 18:31:22 - INFO - __main__ -     global_step = 312\n",
            "\n",
            "12/30/2021 18:31:22 - INFO - __main__ -     loss = 0.0971341119062951\n",
            "\n",
            "12/30/2021 18:31:22 - INFO - __main__ -     test_loss = 0.688785970211029\n",
            "\n",
            "12/30/2021 18:31:22 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  65% 13/20 [01:57<01:03,  9.11s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.67it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.73it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.85it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.80it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.81it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:31:31 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:31 - INFO - __main__ -     epoch = 14\n",
            "\n",
            "12/30/2021 18:31:31 - INFO - __main__ -     global_step = 336\n",
            "\n",
            "12/30/2021 18:31:31 - INFO - __main__ -     loss = 0.09850121326174606\n",
            "\n",
            "12/30/2021 18:31:31 - INFO - __main__ -     test_loss = 0.7400177121162415\n",
            "\n",
            "12/30/2021 18:31:31 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  70% 14/20 [02:06<00:54,  9.09s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.66it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.75it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.80it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.81it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.83it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.82it/s]\n",
            "12/30/2021 18:31:40 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:40 - INFO - __main__ -     epoch = 15\n",
            "\n",
            "12/30/2021 18:31:40 - INFO - __main__ -     global_step = 360\n",
            "\n",
            "12/30/2021 18:31:40 - INFO - __main__ -     loss = 0.07841821957784607\n",
            "\n",
            "12/30/2021 18:31:40 - INFO - __main__ -     test_loss = 0.8330567479133606\n",
            "\n",
            "12/30/2021 18:31:40 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  75% 15/20 [02:15<00:45,  9.08s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.63it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.72it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.77it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.82it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.82it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.82it/s]\n",
            "12/30/2021 18:31:49 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:49 - INFO - __main__ -     epoch = 16\n",
            "\n",
            "12/30/2021 18:31:49 - INFO - __main__ -     global_step = 384\n",
            "\n",
            "12/30/2021 18:31:49 - INFO - __main__ -     loss = 0.046917348160908055\n",
            "\n",
            "12/30/2021 18:31:49 - INFO - __main__ -     test_loss = 0.8844902515411377\n",
            "\n",
            "12/30/2021 18:31:49 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  80% 16/20 [02:24<00:36,  9.07s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.64it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.75it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.80it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.81it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.82it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.85it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.85it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:31:58 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:31:58 - INFO - __main__ -     epoch = 17\n",
            "\n",
            "12/30/2021 18:31:58 - INFO - __main__ -     global_step = 408\n",
            "\n",
            "12/30/2021 18:31:58 - INFO - __main__ -     loss = 0.01738900703821855\n",
            "\n",
            "12/30/2021 18:31:58 - INFO - __main__ -     test_loss = 0.8984044194221497\n",
            "\n",
            "12/30/2021 18:31:58 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  85% 17/20 [02:33<00:27,  9.06s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.66it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.75it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.79it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.85it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.85it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.84it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:32:07 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:32:07 - INFO - __main__ -     epoch = 18\n",
            "\n",
            "12/30/2021 18:32:07 - INFO - __main__ -     global_step = 432\n",
            "\n",
            "12/30/2021 18:32:07 - INFO - __main__ -     loss = 0.009071330380417445\n",
            "\n",
            "12/30/2021 18:32:07 - INFO - __main__ -     test_loss = 0.9116427898406982\n",
            "\n",
            "12/30/2021 18:32:07 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  90% 18/20 [02:43<00:18,  9.06s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.67it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:07,  2.76it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.78it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.81it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.84it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.80it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.82it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.83it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.82it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.82it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.81it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.82it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.82it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.84it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.84it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.82it/s]\n",
            "12/30/2021 18:32:16 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:32:16 - INFO - __main__ -     epoch = 19\n",
            "\n",
            "12/30/2021 18:32:16 - INFO - __main__ -     global_step = 456\n",
            "\n",
            "12/30/2021 18:32:16 - INFO - __main__ -     loss = 0.007900674302921592\n",
            "\n",
            "12/30/2021 18:32:16 - INFO - __main__ -     test_loss = 0.9171066880226135\n",
            "\n",
            "12/30/2021 18:32:16 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch:  95% 19/20 [02:52<00:09,  9.06s/it]\n",
            "Iteration:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/24 [00:00<00:08,  2.66it/s]\u001b[A\n",
            "Iteration:   8% 2/24 [00:00<00:08,  2.75it/s]\u001b[A\n",
            "Iteration:  12% 3/24 [00:01<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  17% 4/24 [00:01<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  21% 5/24 [00:01<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  25% 6/24 [00:02<00:06,  2.83it/s]\u001b[A\n",
            "Iteration:  29% 7/24 [00:02<00:06,  2.82it/s]\u001b[A\n",
            "Iteration:  33% 8/24 [00:02<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  38% 9/24 [00:03<00:05,  2.83it/s]\u001b[A\n",
            "Iteration:  42% 10/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  46% 11/24 [00:03<00:04,  2.84it/s]\u001b[A\n",
            "Iteration:  50% 12/24 [00:04<00:04,  2.85it/s]\u001b[A\n",
            "Iteration:  54% 13/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  58% 14/24 [00:04<00:03,  2.83it/s]\u001b[A\n",
            "Iteration:  62% 15/24 [00:05<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  67% 16/24 [00:05<00:02,  2.84it/s]\u001b[A\n",
            "Iteration:  71% 17/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  75% 18/24 [00:06<00:02,  2.83it/s]\u001b[A\n",
            "Iteration:  79% 19/24 [00:06<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  83% 20/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  88% 21/24 [00:07<00:01,  2.83it/s]\u001b[A\n",
            "Iteration:  92% 22/24 [00:07<00:00,  2.82it/s]\u001b[A\n",
            "Iteration:  96% 23/24 [00:08<00:00,  2.83it/s]\u001b[A\n",
            "Iteration: 100% 24/24 [00:08<00:00,  2.83it/s]\n",
            "12/30/2021 18:32:25 - INFO - __main__ -   ***** Eval results *****\n",
            "12/30/2021 18:32:25 - INFO - __main__ -     epoch = 20\n",
            "\n",
            "12/30/2021 18:32:25 - INFO - __main__ -     global_step = 480\n",
            "\n",
            "12/30/2021 18:32:25 - INFO - __main__ -     loss = 0.005991363472276134\n",
            "\n",
            "12/30/2021 18:32:25 - INFO - __main__ -     test_loss = 0.9180474877357483\n",
            "\n",
            "12/30/2021 18:32:25 - INFO - __main__ -     test_accuracy = 0.875\n",
            "\n",
            "Epoch: 100% 20/20 [03:01<00:00,  9.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdf5UcHUdkYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09ae77b-a260-47d1-fa1c-727ae9b5bdc7"
      },
      "source": [
        "!python evaluation.py --task_name sentihood_NLI_M --pred_data_dir /content/ABSA-BERT-pair/results10/test_ep_10.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"evaluation.py\", line 429, in <module>\n",
            "    main()\n",
            "  File \"evaluation.py\", line 404, in main\n",
            "    aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC = sentihood_AUC_Acc(y_true, score)\n",
            "  File \"evaluation.py\", line 257, in sentihood_AUC_Acc\n",
            "    aspect_auc.append(metrics.roc_auc_score(aspect_y_trues[i], aspect_y_scores[i]))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\", line 572, in roc_auc_score\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\", line 75, in _average_binary_score\n",
            "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\", line 338, in _binary_roc_auc_score\n",
            "    \"Only one class present in y_true. ROC AUC score \"\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZjFohoP8eZ_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}