{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA_Bert_Based.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RV05/NLP-ABSA-research-papers-implementation/blob/main/ABSA_Bert_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ABSA/ABSA-PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBwkqSOcx1fP",
        "outputId": "4afd1e4e-9bcd-4f9d-8f02-dfebddce80a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ABSA/ABSA-PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD4RlBaOx_s-",
        "outputId": "a26590de-216a-4681-97d4-82d9e1aacbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.7 kB/s \n",
            "\u001b[?25hCollecting transformers<4.0.0,>=3.5.1\n",
            "  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (4.62.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.17.3)\n",
            "Collecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.0.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.91 tokenizers-0.9.3 torch-1.4.0 transformers-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ABSA/ABSA-PyTorch/dependency_graph.py --dataset /content/drive/MyDrive/ABSA/ABSA-PyTorch/datasets/semeval14/Enterpret_Train.xml.seg"
      ],
      "metadata": {
        "id": "7G6yXHnHyPCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ABSA/ABSA-PyTorch/dependency_graph.py --dataset /content/drive/MyDrive/ABSA/ABSA-PyTorch/datasets/semeval14/Enterpret_Test_Gold.xml.seg"
      ],
      "metadata": {
        "id": "sv5V761HUcDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ABSA/ABSA-PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmGovSSHUvj_",
        "outputId": "1c3e74bb-8542-4357-9194-ec5fc119ff03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ABSA/ABSA-PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --model_name aen_bert --dataset restaurant --num_epoch 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kiy3dTbyKrc",
        "outputId": "4df34e1e-48eb-4c78-8ab0-b2b2ca51a885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 232k/232k [00:00<00:00, 1.97MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 432kB/s]\n",
            "Downloading: 100% 440M/440M [00:10<00:00, 40.5MB/s]\n",
            "cuda memory allocated: 452894208\n",
            "> n_trainable_params: 112937661, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: aen_bert\n",
            ">>> dataset: restaurant\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f2765d0c3b0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 1\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 10\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 85\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 5\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.aen.AEN_BERT'>\n",
            ">>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}\n",
            ">>> inputs_cols: ['text_bert_indices', 'aspect_bert_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "loss: 1.4709, acc: 0.6188\n",
            "loss: 1.2375, acc: 0.5500\n",
            "loss: 1.1454, acc: 0.5792\n",
            "loss: 1.0938, acc: 0.5797\n",
            "loss: 1.0451, acc: 0.5913\n",
            "loss: 1.0172, acc: 0.6010\n",
            "loss: 0.9930, acc: 0.6080\n",
            "loss: 0.9623, acc: 0.6180\n",
            "loss: 0.9414, acc: 0.6264\n",
            "loss: 0.9169, acc: 0.6356\n",
            "loss: 0.9081, acc: 0.6369\n",
            "loss: 0.8933, acc: 0.6448\n",
            "loss: 0.8871, acc: 0.6481\n",
            "loss: 0.8797, acc: 0.6469\n",
            "loss: 0.8615, acc: 0.6554\n",
            "loss: 0.8515, acc: 0.6574\n",
            "loss: 0.8371, acc: 0.6632\n",
            "loss: 0.8246, acc: 0.6677\n",
            "loss: 0.8123, acc: 0.6727\n",
            "loss: 0.8021, acc: 0.6759\n",
            "loss: 0.7948, acc: 0.6786\n",
            "loss: 0.7801, acc: 0.6841\n",
            "> val_acc: 0.7973, val_f1: 0.6696\n",
            ">> saved: state_dict/aen_bert_restaurant_val_acc_0.7973\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            ">> test_acc: 0.7973, test_f1: 0.6696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python infer_example.py"
      ],
      "metadata": {
        "id": "Ym7eT3r_yO9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105a26e7-f63a-484a-fa81-eb89a0aa949e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading tokenizer: restaurant_tokenizer.dat\n",
            "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n",
            "loading model mgan ...\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "djp2V0cUJcRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HWTcCWUkJcNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vBDBoxCcyO6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DDAr4-fZyO39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}